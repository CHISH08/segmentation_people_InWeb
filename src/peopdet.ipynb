{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"12\"\n",
    "# os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"12\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "# import albumentations as A\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "from tensorflow.keras.layers import Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, Input, concatenate\n",
    "from multiprocessing import Pool\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "my_devices = tf.config.experimental.list_physical_devices(device_type='CPU') \n",
    "tf.config.experimental.set_visible_devices(devices=my_devices, device_type='CPU')\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPU, 1 Logical GPUs\n",
      "1 Physical CPU, 1 Logical CPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus: \n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=4100)]\n",
    "    )\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "cpus = tf.config.list_physical_devices('CPU')\n",
    "logical_cpus = tf.config.list_logical_devices('CPU')\n",
    "print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   try:\n",
    "#     for gpu in gpus:\n",
    "#       tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#   except RuntimeError as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 384\n",
    "IMG_WIDTH = 384\n",
    "nb_filter = [32,64,128,256,512]\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * tf.keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_path = \"./input2\"\n",
    "Y_path = \"./Output2\"\n",
    "img = sorted([os.path.join(dp, f) for dp, dn, filenames in os.walk(X_path) for f in filenames if os.path.splitext(f)[1] == '.png' or os.path.splitext(f)[1] == '.jpg'])\n",
    "mask = sorted([os.path.join(dp, f) for dp, dn, filenames in os.walk(Y_path) for f in filenames if os.path.splitext(f)[1] == '.png' or os.path.splitext(f)[1] == '.jpg'])\n",
    "X_path = \"./images2\"\n",
    "Y_path = \"./masks2\"\n",
    "img += sorted([os.path.join(dp, f) for dp, dn, filenames in os.walk(X_path) for f in filenames if os.path.splitext(f)[1] == '.png' or os.path.splitext(f)[1] == '.jpg'])\n",
    "mask += sorted([os.path.join(dp, f) for dp, dn, filenames in os.walk(Y_path) for f in filenames if os.path.splitext(f)[1] == '.png' or os.path.splitext(f)[1] == '.jpg'])\n",
    "image_list_train, image_list_val, mask_list_train, mask_list_val = train_test_split(img, mask, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_image(arg):\n",
    "#     image_path, mask_path, i = arg\n",
    "#     x = Image.open(image_path)\n",
    "#     y = Image.open(mask_path)\n",
    "#     for j in range(2):\n",
    "#         transform = A.Compose([\n",
    "#             A.HorizontalFlip(p=0.5),\n",
    "#             A.ShiftScaleRotate(border_mode=cv2.BORDER_CONSTANT, \n",
    "#                                 scale_limit=0.3,\n",
    "#                                 rotate_limit=(10, 30),\n",
    "#                                 p=0.7),\n",
    "#             # A.GridDistortion(p=0.5),\n",
    "#             A.OpticalDistortion(p=0.5),\n",
    "#             A.GaussianBlur(p=0.5),\n",
    "#             A.Equalize(p=0.5),\n",
    "#             A.RandomBrightnessContrast(p=0.5),\n",
    "#             A.RandomGamma(p=0.5)\n",
    "#         ])\n",
    "#         transformed = transform(image=np.array(x), mask=np.array(y))\n",
    "\n",
    "#         image_trans = transformed['image']\n",
    "#         mask_trans = transformed['mask']\n",
    "#         x = Image.fromarray(image_trans)\n",
    "#         y = Image.fromarray(mask_trans)\n",
    "#         x.save(f'./input2/{i}v{j}.jpg')\n",
    "#         y.save(f'./Output2/{i}v{j}.png', 'PNG')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     img = sorted([str(os.path.join(dp, f)) for dp, dn, filenames in os.walk(X_path) for f in filenames if os.path.splitext(f)[1] == '.png' or os.path.splitext(f)[1] == '.jpg'])\n",
    "#     mask = sorted([str(os.path.join(dp, f)) for dp, dn, filenames in os.walk(Y_path) for f in filenames if os.path.splitext(f)[1] == '.png' or os.path.splitext(f)[1] == '.jpg'])\n",
    "#     args_list = [(image_path, mask_path, i) for i, (image_path, mask_path) in enumerate(zip(img, mask))]\n",
    "#     with Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "#         list(tqdm(pool.imap(process_image, args_list), total=len(args_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image_and_mask(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (IMG_HEIGHT, IMG_WIDTH), method=\"bicubic\")\n",
    "    image = tf.cast(image, dtype=tf.float32) / 255.\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=3)\n",
    "    mask = tf.image.resize(mask, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    mask = tf.reduce_all(mask == 0, axis=-1, keepdims=True)\n",
    "    mask = tf.cast(not(mask), dtype=tf.float32)\n",
    "    \n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((img, mask))\n",
    "dataset_train = dataset_train.shuffle(buffer_size=100000).map(load_image_and_mask, num_parallel_calls=AUTOTUNE).batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((image_list_val, mask_list_val))\n",
    "dataset_val = dataset_val.shuffle(buffer_size=100000).map(load_image_and_mask, num_parallel_calls=AUTOTUNE).batch(batch_size).prefetch(AUTOTUNE)\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, n_batches):\n",
    "        test_Path = \"/home/denis/Изображения/Веб-камера\"\n",
    "        self.n_batches = n_batches\n",
    "        self.img_test = sorted([os.path.join(dp, f) for dp, dn, filenames in os.walk(test_Path) for f in filenames if os.path.splitext(f)[1] == '.png' or os.path.splitext(f)[1] == '.jpg'])\n",
    "        self.dataset_test = tf.data.Dataset.from_tensor_slices((self.img_test, self.img_test)).map(load_image_and_mask).batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch % self.n_batches == 0:\n",
    "            fig = plt.figure(figsize=(36,13))\n",
    "            for k, (x, _) in enumerate(self.dataset_test):\n",
    "                y_pred = self.model.predict(x)\n",
    "                for i in range(y_pred.shape[0]):\n",
    "                    fig.add_subplot(3, batch_size*len(self.dataset_test), i+k*batch_size+1)\n",
    "                    plt.imshow(y_pred[i])\n",
    "                    plt.title('Predicted mask')\n",
    "                    plt.axis('off')\n",
    "                    mask = (y_pred[i] < 0.9)\n",
    "                    mask = tf.where(mask, tf.ones_like(x[i]), x[i])\n",
    "                    mask = tf.image.resize(mask, size=(384, 384), method='area')\n",
    "                    mask = mask.numpy()\n",
    "                    fig.add_subplot(3, batch_size*len(self.dataset_test), i+k*batch_size+batch_size*len(self.dataset_test)+1)\n",
    "                    plt.imshow(mask, cmap=\"gray\")\n",
    "                    plt.title('Predicted image')\n",
    "                    plt.axis('off')\n",
    "                    fig.add_subplot(3, batch_size*len(self.dataset_test), i+k*batch_size+2*batch_size*len(self.dataset_test)+1)\n",
    "                    plt.imshow(x[i], cmap=\"gray\")\n",
    "                    plt.title('Image')\n",
    "                    plt.axis('off')\n",
    "            clear_output()\n",
    "            plt.show()\n",
    "        if (batch % 1000) == 0 and batch >= 1000:\n",
    "            self.model.save(f\"save_model/model{batch}\")\n",
    "            # lst = random.sample(range(len(self.model.layers)),1)\n",
    "            # for i in lst:\n",
    "            #     self.model.layers[i].trainable = False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in dataset_train:\n",
    "#     fig = plt.figure(figsize=(36,13))\n",
    "#     for i in range(len(x)):\n",
    "#         # clear_output(wait=True)\n",
    "#         fig.add_subplot(2, len(x), i+1)\n",
    "#         plt.imshow(y[i], cmap=\"gray\")\n",
    "#         plt.axis('off')\n",
    "#         fig.add_subplot(2, len(x), i+len(x)+1)\n",
    "#         plt.imshow(x[i], cmap=\"gray\")\n",
    "#         plt.axis('off')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    def convolution_block(\n",
    "        block_input,\n",
    "        num_filters=256,\n",
    "        kernel_size=3,\n",
    "        dilation_rate=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "    ):\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            num_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            padding=padding,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "        )(block_input)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "    def DilatedSpatialPyramidPooling(dspp_input):\n",
    "        dims = dspp_input.shape\n",
    "        dspp_input = tf.keras.layers.BatchNormalization()(dspp_input)\n",
    "        x = tf.keras.layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "        x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "        out_pool = tf.keras.layers.UpSampling2D(\n",
    "            size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"nearest\" # nearest\n",
    "        )(x)\n",
    "\n",
    "        out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "        out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "        out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "        out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "        x = tf.keras.layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "        output = convolution_block(x, kernel_size=1)\n",
    "        return output\n",
    "    \n",
    "    def DeeplabV3Plus(input_shape, num_classes):\n",
    "        model_input = tf.keras.Input(shape=input_shape)\n",
    "        resnet50 = tf.keras.applications.ResNet50(\n",
    "            weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
    "        )\n",
    "        # print(len(resnet50.layers))\n",
    "        x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "        x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "        input_a = tf.keras.layers.UpSampling2D(\n",
    "            size=(input_shape[0] // 4 // x.shape[1], input_shape[0] // 4 // x.shape[2]),\n",
    "            interpolation=\"bilinear\",\n",
    "        )(x)\n",
    "        input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "        input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "        x = tf.keras.layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "        x = convolution_block(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        x = convolution_block(x)\n",
    "        x = tf.keras.layers.UpSampling2D(\n",
    "            size=(input_shape[0] // x.shape[1], input_shape[0] // x.shape[2]),\n",
    "            interpolation=\"bilinear\",\n",
    "        )(x)\n",
    "        model_output = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\", activation=\"sigmoid\")(x)\n",
    "        return tf.keras.Model(inputs=model_input, outputs=model_output)\n",
    "    custom_objects = {'bce_dice_loss': bce_dice_loss}\n",
    "\n",
    "# Load the model with the custom_objects argument\n",
    "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "        model = tf.keras.models.load_model(\"save_model/model26000\") # save_model800\n",
    "        # model.layers[-2].interpolation = 'bilinear'\n",
    "    # model = DeeplabV3Plus((IMG_HEIGHT, IMG_WIDTH, 3), 1)\n",
    "    # scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    #         initial_learning_rate=3*1e-4,\n",
    "    #         decay_steps=20000,\n",
    "    #         decay_rate=0.8\n",
    "    #     )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=3*1e-5,use_ema=True, ema_momentum=0.5),\n",
    "        loss=bce_dice_loss,\n",
    "        metrics=tf.keras.metrics.BinaryIoU(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def unetplus(input=(384, 384, 256) , activation='elu'):\n",
    "        inputs = Input(input)\n",
    "\n",
    "        c1 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (inputs)\n",
    "        # c1 = Dropout(0.5) (c1)\n",
    "        c1 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c1)\n",
    "        # c1 = Dropout(0.5) (c1)\n",
    "        p1 = MaxPooling2D((2, 2), strides=(2, 2)) (c1)\n",
    "\n",
    "        c2 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (p1)\n",
    "        # c2 = Dropout(0.5) (c2)\n",
    "        c2 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c2)\n",
    "        # c2 = Dropout(0.5) (c2)\n",
    "        p2 = MaxPooling2D((2, 2), strides=(2, 2)) (c2)\n",
    "\n",
    "        up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(c2)\n",
    "        conv1_2 = concatenate([up1_2, c1], name='merge12', axis=3)\n",
    "        c3 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv1_2)\n",
    "        # c3 = Dropout(0.5) (c3)\n",
    "        c3 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c3)\n",
    "        # c3 = Dropout(0.5) (c3)\n",
    "\n",
    "        conv3_1 = Conv2D(128, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (p2)\n",
    "        # conv3_1 = Dropout(0.5) (conv3_1)\n",
    "        conv3_1 = Conv2D(128, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv3_1)\n",
    "        # conv3_1 = Dropout(0.5) (conv3_1)\n",
    "        pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n",
    "\n",
    "        up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n",
    "        conv2_2 = concatenate([up2_2, c2], name='merge22', axis=3) #x10\n",
    "        conv2_2 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv2_2)\n",
    "        # conv2_2 = Dropout(0.5) (conv2_2)\n",
    "        conv2_2 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv2_2)\n",
    "        # conv2_2 = Dropout(0.5) (conv2_2)\n",
    "\n",
    "        up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n",
    "        conv1_3 = concatenate([up1_3, c1, c3], name='merge13', axis=3)\n",
    "        conv1_3 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv1_3)\n",
    "        # conv1_3 = Dropout(0.5) (conv1_3)\n",
    "        conv1_3 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv1_3)\n",
    "        # conv1_3 = Dropout(0.5) (conv1_3)\n",
    "\n",
    "        conv4_1 = Conv2D(256, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (pool3)\n",
    "        # conv4_1 = Dropout(0.5) (conv4_1)\n",
    "        conv4_1 = Conv2D(256, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv4_1)\n",
    "        # conv4_1 = Dropout(0.5) (conv4_1)\n",
    "        pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n",
    "\n",
    "        up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n",
    "        conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=3) #x20\n",
    "        conv3_2 = Conv2D(128, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv3_2)\n",
    "        # conv3_2 = Dropout(0.5) (conv3_2)\n",
    "        conv3_2 = Conv2D(128, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv3_2)\n",
    "        conv3_2 = Dropout(0.5) (conv3_2)\n",
    "\n",
    "        up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n",
    "        conv2_3 = concatenate([up2_3, c2, conv2_2], name='merge23', axis=3)\n",
    "        conv2_3 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv2_3)\n",
    "        # conv2_3 = Dropout(0.5) (conv2_3)\n",
    "        conv2_3 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv2_3)\n",
    "        # conv2_3 = Dropout(0.5) (conv2_3)\n",
    "\n",
    "        up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n",
    "        conv1_4 = concatenate([up1_4, c1, c3, conv1_3], name='merge14', axis=3)\n",
    "        conv1_4 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv1_4)\n",
    "        conv1_4 = Dropout(0.5) (conv1_4)\n",
    "        conv1_4 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv1_4)\n",
    "        # conv1_4 = Dropout(0.5) (conv1_4)\n",
    "\n",
    "        conv5_1 = Conv2D(512, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (pool4)\n",
    "        # conv5_1 = Dropout(0.5) (conv5_1)\n",
    "        conv5_1 = Conv2D(512, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv5_1)\n",
    "        # conv5_1 = Dropout(0.5) (conv5_1)\n",
    "\n",
    "        up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n",
    "        conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=3) #x30\n",
    "        conv4_2 = Conv2D(256, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv4_2)\n",
    "        # conv4_2 = Dropout(0.5) (conv4_2)\n",
    "        conv4_2 = Conv2D(256, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv4_2)\n",
    "        # conv4_2 = Dropout(0.5) (conv4_2)\n",
    "\n",
    "        up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n",
    "        conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=3)\n",
    "        conv3_3 = Conv2D(128, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv3_3)\n",
    "        conv3_3 = Dropout(0.5) (conv3_3)\n",
    "        conv3_3 = Conv2D(128, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv3_3)\n",
    "        # conv3_3 = Dropout(0.5) (conv3_3)\n",
    "\n",
    "        up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n",
    "        conv2_4 = concatenate([up2_4, c2, conv2_2, conv2_3], name='merge24', axis=3)\n",
    "        conv2_4 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv2_4)\n",
    "        # conv2_4 = Dropout(0.5) (conv2_4)\n",
    "        conv2_4 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv2_4)\n",
    "        # conv2_4 = Dropout(0.5) (conv2_4)\n",
    "\n",
    "        up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n",
    "        conv1_5 = concatenate([up1_5, c1, c3, conv1_3, conv1_4], name='merge15', axis=3)\n",
    "        conv1_5 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv1_5)\n",
    "        # conv1_5 = Dropout(0.5) (conv1_5)\n",
    "        conv1_5 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (conv1_5)\n",
    "        # conv1_5 = Dropout(0.5) (conv1_5)\n",
    "\n",
    "        nestnet_output_4 = Conv2D(1, (1, 1), activation='sigmoid', kernel_initializer = 'he_normal',  name='output_4', padding='same')(conv1_5)\n",
    "\n",
    "        return tf.keras.Model([inputs], [nestnet_output_4])\n",
    "    model2 = unetplus()\n",
    "    # scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    #         initial_learning_rate=1e-5,\n",
    "    #         decay_steps=1000,\n",
    "    #         decay_rate=0.8\n",
    "    #     )\n",
    "    # model2.compile(\n",
    "    #     optimizer=tf.keras.optimizers.Adam(learning_rate=scheduler),\n",
    "    #     loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    #     metrics=tf.keras.metrics.BinaryIoU(),\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 1., 1: 1.5}\n",
    "history = model.fit(dataset_train, epochs=1, callbacks=[SegmentationCallback(n_batches=100)], use_multiprocessing=True, workers=os.cpu_count(), class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Path = \"/home/denis/Изображения/Веб-камера\"\n",
    "img_test = sorted([os.path.join(dp, f) for dp, dn, filenames in os.walk(test_Path) for f in filenames if os.path.splitext(f)[1] == '.png' or os.path.splitext(f)[1] == '.jpg'])\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((img_test, img_test)).map(load_image_and_mask).batch(batch_size)\n",
    "custom_objects = {'bce_dice_loss': bce_dice_loss}\n",
    "for j in range(1000, 31001, 1000):\n",
    "    \n",
    "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "        model = tf.keras.models.load_model(f\"save_model/model{j}\")\n",
    "    # model2 = tf.keras.models.load_model(f\"save_model/model{j}\")\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False\n",
    "    for k, (x, _) in enumerate(dataset_test):\n",
    "        # clear_output(100000)\n",
    "        y_pred = model.predict(x)\n",
    "        fig = plt.figure(figsize=(16,9))\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            fig.add_subplot(3, y_pred.shape[0], i+1)\n",
    "            plt.imshow(y_pred[i], cmap=\"gray\")\n",
    "            plt.title('Predicted mask')\n",
    "            plt.axis('off')\n",
    "            mask = (y_pred[i] < 0.9)\n",
    "            mask = tf.where(mask, tf.ones_like(x[i]), x[i])\n",
    "            mask = tf.image.resize(mask, size=(384, 384), method='area')\n",
    "            mask = mask.numpy()\n",
    "            fig.add_subplot(3, y_pred.shape[0], i+y_pred.shape[0]+1)\n",
    "            plt.imshow(mask, cmap=\"gray\")\n",
    "            plt.title('Predicted image')\n",
    "            plt.axis('off')\n",
    "            fig.add_subplot(3, y_pred.shape[0], i+2*y_pred.shape[0]+1)\n",
    "            plt.imshow(x[i], cmap=\"gray\")\n",
    "            plt.title('Image')\n",
    "            plt.axis('off')\n",
    "        # clear_output(wait=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mod/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mod/assets\n"
     ]
    }
   ],
   "source": [
    "custom_objects = {'bce_dice_loss': bce_dice_loss}\n",
    "model = tf.keras.models.load_model(\"save_end_model/model12000\", custom_objects=custom_objects)\n",
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=3*1e-5,use_ema=True, ema_momentum=0.5),\n",
    "        loss=\"bce\",\n",
    "        metrics=tf.keras.metrics.BinaryIoU(),\n",
    "    )\n",
    "model.save(\"mod\", save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
